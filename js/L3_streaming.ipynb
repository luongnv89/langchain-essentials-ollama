{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32715af",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210c316",
   "metadata": {},
   "source": [
    "Let's start by setting up a basic agent to demonstrate different streaming approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import * as setup from \"./setup.ts\";\n",
    "import { createAgent } from \"langchain\";\n",
    "\n",
    "const agent = createAgent({\n",
    "    model: \"anthropic:claude-sonnet-4-5-20250929\",\n",
    "    systemPrompt: \"You are a full-stack comedian\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f069f4",
   "metadata": {},
   "source": [
    "Now that we have our agent configured, let's first see how it works without streaming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29796de7",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessage } from \"langchain\";\n",
    "\n",
    "const result = await agent.invoke({\n",
    "    messages: [new HumanMessage(\"Tell me a joke\")]\n",
    "})\n",
    "\n",
    "console.log(result.messages.at(-1).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e26011",
   "metadata": {},
   "source": [
    "Notice how we had to wait for the complete response. Let's improve the user experience with streaming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87f8c8",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "### `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "const stream = await agent.stream({\n",
    "    messages: [new HumanMessage(\"Tell me a joke\")],\n",
    "}, {\n",
    "    streamMode: \"values\",\n",
    "})\n",
    "\n",
    "for await (const step of stream) {\n",
    "    console.log(step.messages.at(-1).content)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832216a",
   "metadata": {},
   "source": [
    "The `values` mode streams the entire state at each step. This is useful when you want to see the full message history as it evolves.\n",
    "\n",
    "### `messages`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4f006",
   "metadata": {},
   "source": [
    "For a more granular experience, `messages` mode streams individual message chunks as they're generated - perfect for real-time token-by-token display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "const stream = await agent.stream({\n",
    "    messages: [new HumanMessage(\"Tell me a joke\")],\n",
    "}, {\n",
    "    streamMode: \"messages\",\n",
    "})\n",
    "\n",
    "for await (const [message, metadata] of stream) {\n",
    "    console.log(`[${metadata.langgraph_node}]: ${message.content}`)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a85884",
   "metadata": {},
   "source": [
    "Here's a more dramatic example - streaming a poem token by token creates a typewriter effect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await Deno.jupyter.broadcast(\"display_data\", {\n",
    "    data: { \"text/markdown\": \"ðŸ¤”\" },\n",
    "    metadata: {},\n",
    "    transient: { display_id: \"progress\" }\n",
    "});\n",
    "\n",
    "const stream = await agent.stream({\n",
    "    messages: [new HumanMessage(\"Write me a poem.\")],\n",
    "}, {\n",
    "    streamMode: \"messages\",\n",
    "})\n",
    "\n",
    "let content = \"\";\n",
    "const i = setInterval(async () => {\n",
    "    Deno.jupyter.broadcast(\"update_display_data\", {\n",
    "        data: { \"text/markdown\": content },\n",
    "        metadata: {},\n",
    "        transient: { display_id: \"progress\" }\n",
    "    });\n",
    "}, 1)\n",
    "\n",
    "for await (const [message, metadata] of stream) {\n",
    "    content += message.content\n",
    "}\n",
    "\n",
    "clearInterval(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca59df5",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A stream writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[36mâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\u001b[0m\n",
      "\u001b[36mâ”‚ ðŸ‘¤ HUMAN MESSAGE                                           â”‚\u001b[0m\n",
      "\u001b[36mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "What's the weather in SF?\n",
      "\n",
      "\u001b[35mâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\u001b[0m\n",
      "\u001b[35mâ”‚ ðŸ¤– AI MESSAGE                                              â”‚\u001b[0m\n",
      "\u001b[35mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "[\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_01QgYgp7Ux4R8mfthYDgt3Rn\",\n",
      "    name: \"get_weather\",\n",
      "    input: { city: \"San Francisco\" }\n",
      "  }\n",
      "]\n",
      "\n",
      "\u001b[33mâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\u001b[0m\n",
      "\u001b[33mâ”‚ ðŸ”§ TOOL MESSAGE                                            â”‚\u001b[0m\n",
      "\u001b[33mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "It's always sunny in San Francisco\n",
      "\n",
      "\u001b[35mâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\u001b[0m\n",
      "\u001b[35mâ”‚ ðŸ¤– AI MESSAGE                                              â”‚\u001b[0m\n",
      "\u001b[35mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "The weather in San Francisco is sunny!\n"
     ]
    }
   ],
   "source": [
    "import * as setup from \"./setup.ts\";\n",
    "import { z } from \"zod\";\n",
    "import { createAgent, tool, type Runtime } from \"langchain\";\n",
    "\n",
    "const getWeather = tool(({ city }, runtime: Runtime) => {\n",
    "    runtime.writer(`Looking up data for city: ${city}`);\n",
    "    runtime.writer(`Acquired data for city: ${city}`);\n",
    "    return `It's always sunny in ${city}`\n",
    "}, {\n",
    "    name: \"get_weather\",\n",
    "    description: \"Get weather for a given city.\",\n",
    "    schema: z.object({\n",
    "        city: z.string()\n",
    "    })\n",
    "});\n",
    "\n",
    "const toolCallingAgent = createAgent({\n",
    "    model: \"anthropic:claude-sonnet-4-5-20250929\",\n",
    "    tools: [getWeather]\n",
    "})\n",
    "\n",
    "const stream = await toolCallingAgent.stream({\n",
    "    messages: \"What's the weather in SF?\",\n",
    "}, {\n",
    "    streamMode: [\"values\", \"custom\"],\n",
    "})\n",
    "\n",
    "for await (const [type, stateOrCustomEvent] of stream) {\n",
    "    if (type === \"values\") {\n",
    "        displayMessage(stateOrCustomEvent.messages.at(-1))\n",
    "    } else if (type === \"custom\") {\n",
    "        displayMessage({\n",
    "            type,\n",
    "            content: stateOrCustomEvent\n",
    "        })\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3c87d",
   "metadata": {},
   "source": [
    "## Try your own.\n",
    "Create a tool of your own and try it here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42797464",
   "metadata": {},
   "outputs": [],
   "source": [
    "const stream = await agent.stream({\n",
    "    messages: \"What's the weather in SF?\",\n",
    "}, {\n",
    "    streamMode: [\"values\", \"custom\"],\n",
    "})\n",
    "\n",
    "for await (const [type, chunk] of stream) {\n",
    "    if (type === \"custom\") {\n",
    "        console.log(chunk)\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
