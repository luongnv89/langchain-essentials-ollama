{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=<not set>\n",
      "LANGSMITH_API_KEY=****4abe\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ad-6\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b\",\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Why did the fullâ€‘stack developer break up with the database?**  \n",
      "\n",
      "Because every time they tried to commit, the DB replied, *â€œI canâ€™t even.â€*  \n",
      "\n",
      "And the developer, still hopeful, said, â€œYouâ€™re just *schema* away from my heart!â€  \n",
      "\n",
      "â€” *Now thatâ€™s a classic relational romance.*\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't skeletons fight each other?  \n",
      "\n",
      "They don't have the guts! ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Great Family Picnic Fiasco**\n",
      "\n",
      "We packed a picnic basket, full of treats,  \n",
      "A sandwich, a cookie, a jar of sweets.  \n",
      "Grandpa said, â€œLetâ€™s spread out on the green,  \n",
      "And watch the clouds float on a lazy stream.â€\n",
      "\n",
      "The kids all ran, the dog barked loud,  \n",
      "The sandwich fell to the proud lawn.  \n",
      "Mamaâ€™s â€œcherry pieâ€ was a perfect sphere,  \n",
      "But it landed on the cat, who didnâ€™t care!\n",
      "\n",
      "A bird flew in, ate crumbs from the plate,  \n",
      "The kids giggled as it chirped, â€œThatâ€™s great!â€  \n",
      "The dog, it chased the bird around,  \n",
      "While Grandpa laughed and said, â€œIâ€™m still sound.â€\n",
      "\n",
      "We found a pond that was oddly cold,  \n",
      "The kids splashed in, so brave and bold.  \n",
      "Mama whispered, â€œLetâ€™s not get wet,  \n",
      "Weâ€™re just a family, not a pet.â€\n",
      "\n",
      "The sun began to set, the sky turned gold,  \n",
      "We gathered back in the eveningâ€™s fold.  \n",
      "We laughed about the picnicâ€™s chaotic fun,  \n",
      "And promised next time to just use the oneâ€”  \n",
      "\n",
      "The umbrella!  \n",
      "So the next picnic, weâ€™ll stay dry,  \n",
      "But the memoriesâ€”yesâ€”will never die.  \n",
      "\n",
      "---  \n",
      "\n",
      "*Family is a comedyâ€”sometimes a bit messy,  \n",
      "But loveâ€™s the punchline that keeps everyone happy.*"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241})]})\n",
      "('custom', 'Looking up data for city: San Francisco')\n",
      "('custom', 'Acquired data for city: San Francisco')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='5d3c9491-53b1-4fdc-b8fd-d15a89aed09e', tool_call_id='e0dca267-5e46-4332-aca2-1ee7e54c4b21')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='5d3c9491-53b1-4fdc-b8fd-d15a89aed09e', tool_call_id='e0dca267-5e46-4332-aca2-1ee7e54c4b21'), AIMessage(content='Iâ€™m sorry about thatâ€”my earlier reply was a generic placeholder. I donâ€™t have live weather data on hand, but hereâ€™s how you can find the current conditions in San\\u202fFrancisco:\\n\\n| Source | How to Check |\\n|--------|--------------|\\n| **Weather Apps** (e.g., Weather\\u202f.com, AccuWeather, Weather Underground) | Open the app or website, enter â€œSan\\u202fFranciscoâ€ and youâ€™ll see temperature, humidity, wind, and a shortâ€‘term forecast. |\\n| **Smartphone Assistants** (Siri, Google Assistant, Alexa) | Say â€œWhatâ€™s the weather in San\\u202fFrancisco?â€ and youâ€™ll get an audible report. |\\n| **Local News Sites** (e.g., KGO, NBC Bay Area) | Many local stations post hourly forecasts on their sites. |\\n| **Government NOAA** | Visit the NOAA Weather Forecast Office for the San\\u202fFrancisco Bay Area (e.g., *NOAA Forecast Office San\\u202fFrancisco*). |\\n\\nIf youâ€™d like a quick snapshot, you can also type â€œSF weatherâ€ into your browser search bar and the builtâ€‘in weather card will appear at the top of the results. That should give you the current temperature, chance of rain, wind speed, and a 5â€‘day outlook.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:58.997665Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8890634917, 'load_duration': 139845667, 'prompt_eval_count': 164, 'prompt_eval_duration': 147945875, 'eval_count': 531, 'eval_duration': 8455833123, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--56d5b175-7913-45cb-b8b4-6a15c80ad277-0', usage_metadata={'input_tokens': 164, 'output_tokens': 531, 'total_tokens': 695})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the weather in SF?It's always sunny in San Francisco!Iâ€™m sorry for the mistake earlier. The function call you saw didnâ€™t return the actual current weatherâ€”it just gave a generic â€œalways sunnyâ€ response.\n",
      "\n",
      "I donâ€™t have realâ€‘time data in this chat, but hereâ€™s what you can do to get an upâ€‘toâ€‘date forecast for Sanâ€¯Francisco:\n",
      "\n",
      "| Method | How to use it |\n",
      "|--------|---------------|\n",
      "| **Weather app on your phone** | Open the builtâ€‘in weather app or a thirdâ€‘party app (e.g., AccuWeather, Weather Underground). |\n",
      "| **Web search** | Go to a search engine and type â€œSan Francisco weatherâ€ to see the latest forecast, temperature, humidity, wind, and alerts. |\n",
      "| **Voice assistants** | Ask Siri, Google Assistant, or Alexa â€œWhatâ€™s the weather in Sanâ€¯Francisco?â€ |\n",
      "| **Local news** | Check the local news stationâ€™s website or channel for a weather segment. |\n",
      "\n",
      "If youâ€™d like me to provide the *average* conditions for this time of year: early October in Sanâ€¯Francisco typically sees temperatures ranging from 56â€¯Â°F (13â€¯Â°C) in the morning to 68â€¯Â°F (20â€¯Â°C) in the afternoon, with a chance of light rain and generally clear skies.\n",
      "\n",
      "Let me know if thereâ€™s anything else youâ€™d like to know!"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])\n",
    "    if chunk[0] == \"values\":\n",
    "        print(chunk[1][\"messages\"][-1].content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
