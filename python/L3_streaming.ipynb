{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=<not set>\n",
      "LANGSMITH_API_KEY=****4abe\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ad-6\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b\",\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Why did the full‚Äëstack developer break up with the database?**  \n",
      "\n",
      "Because every time they tried to commit, the DB replied, *‚ÄúI can‚Äôt even.‚Äù*  \n",
      "\n",
      "And the developer, still hopeful, said, ‚ÄúYou‚Äôre just *schema* away from my heart!‚Äù  \n",
      "\n",
      "‚Äî *Now that‚Äôs a classic relational romance.*\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't skeletons fight each other?  \n",
      "\n",
      "They don't have the guts! üòÑ\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Great Family Picnic Fiasco**\n",
      "\n",
      "We packed a picnic basket, full of treats,  \n",
      "A sandwich, a cookie, a jar of sweets.  \n",
      "Grandpa said, ‚ÄúLet‚Äôs spread out on the green,  \n",
      "And watch the clouds float on a lazy stream.‚Äù\n",
      "\n",
      "The kids all ran, the dog barked loud,  \n",
      "The sandwich fell to the proud lawn.  \n",
      "Mama‚Äôs ‚Äúcherry pie‚Äù was a perfect sphere,  \n",
      "But it landed on the cat, who didn‚Äôt care!\n",
      "\n",
      "A bird flew in, ate crumbs from the plate,  \n",
      "The kids giggled as it chirped, ‚ÄúThat‚Äôs great!‚Äù  \n",
      "The dog, it chased the bird around,  \n",
      "While Grandpa laughed and said, ‚ÄúI‚Äôm still sound.‚Äù\n",
      "\n",
      "We found a pond that was oddly cold,  \n",
      "The kids splashed in, so brave and bold.  \n",
      "Mama whispered, ‚ÄúLet‚Äôs not get wet,  \n",
      "We‚Äôre just a family, not a pet.‚Äù\n",
      "\n",
      "The sun began to set, the sky turned gold,  \n",
      "We gathered back in the evening‚Äôs fold.  \n",
      "We laughed about the picnic‚Äôs chaotic fun,  \n",
      "And promised next time to just use the one‚Äî  \n",
      "\n",
      "The umbrella!  \n",
      "So the next picnic, we‚Äôll stay dry,  \n",
      "But the memories‚Äîyes‚Äîwill never die.  \n",
      "\n",
      "---  \n",
      "\n",
      "*Family is a comedy‚Äîsometimes a bit messy,  \n",
      "But love‚Äôs the punchline that keeps everyone happy.*"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241})]})\n",
      "('custom', 'Looking up data for city: San Francisco')\n",
      "('custom', 'Acquired data for city: San Francisco')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='5d3c9491-53b1-4fdc-b8fd-d15a89aed09e', tool_call_id='e0dca267-5e46-4332-aca2-1ee7e54c4b21')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='c793f77f-b494-41b0-941f-dc60d9a88739'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:50.099134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7335305333, 'load_duration': 163918833, 'prompt_eval_count': 128, 'prompt_eval_duration': 5358105750, 'eval_count': 113, 'eval_duration': 1776516955, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--37dfbec9-9e37-4b83-927b-67e3864bb3c8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'e0dca267-5e46-4332-aca2-1ee7e54c4b21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 128, 'output_tokens': 113, 'total_tokens': 241}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='5d3c9491-53b1-4fdc-b8fd-d15a89aed09e', tool_call_id='e0dca267-5e46-4332-aca2-1ee7e54c4b21'), AIMessage(content='I‚Äôm sorry about that‚Äîmy earlier reply was a generic placeholder. I don‚Äôt have live weather data on hand, but here‚Äôs how you can find the current conditions in San\\u202fFrancisco:\\n\\n| Source | How to Check |\\n|--------|--------------|\\n| **Weather Apps** (e.g., Weather\\u202f.com, AccuWeather, Weather Underground) | Open the app or website, enter ‚ÄúSan\\u202fFrancisco‚Äù and you‚Äôll see temperature, humidity, wind, and a short‚Äëterm forecast. |\\n| **Smartphone Assistants** (Siri, Google Assistant, Alexa) | Say ‚ÄúWhat‚Äôs the weather in San\\u202fFrancisco?‚Äù and you‚Äôll get an audible report. |\\n| **Local News Sites** (e.g., KGO, NBC Bay Area) | Many local stations post hourly forecasts on their sites. |\\n| **Government NOAA** | Visit the NOAA Weather Forecast Office for the San\\u202fFrancisco Bay Area (e.g., *NOAA Forecast Office San\\u202fFrancisco*). |\\n\\nIf you‚Äôd like a quick snapshot, you can also type ‚ÄúSF weather‚Äù into your browser search bar and the built‚Äëin weather card will appear at the top of the results. That should give you the current temperature, chance of rain, wind speed, and a 5‚Äëday outlook.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-10-28T10:07:58.997665Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8890634917, 'load_duration': 139845667, 'prompt_eval_count': 164, 'prompt_eval_duration': 147945875, 'eval_count': 531, 'eval_duration': 8455833123, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--56d5b175-7913-45cb-b8b4-6a15c80ad277-0', usage_metadata={'input_tokens': 164, 'output_tokens': 531, 'total_tokens': 695})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"ollama:gpt-oss:20b\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the weather in SF?It's always sunny in San Francisco!I‚Äôm sorry for the mistake earlier. The function call you saw didn‚Äôt return the actual current weather‚Äîit just gave a generic ‚Äúalways sunny‚Äù response.\n",
      "\n",
      "I don‚Äôt have real‚Äëtime data in this chat, but here‚Äôs what you can do to get an up‚Äëto‚Äëdate forecast for San‚ÄØFrancisco:\n",
      "\n",
      "| Method | How to use it |\n",
      "|--------|---------------|\n",
      "| **Weather app on your phone** | Open the built‚Äëin weather app or a third‚Äëparty app (e.g., AccuWeather, Weather Underground). |\n",
      "| **Web search** | Go to a search engine and type ‚ÄúSan Francisco weather‚Äù to see the latest forecast, temperature, humidity, wind, and alerts. |\n",
      "| **Voice assistants** | Ask Siri, Google Assistant, or Alexa ‚ÄúWhat‚Äôs the weather in San‚ÄØFrancisco?‚Äù |\n",
      "| **Local news** | Check the local news station‚Äôs website or channel for a weather segment. |\n",
      "\n",
      "If you‚Äôd like me to provide the *average* conditions for this time of year: early October in San‚ÄØFrancisco typically sees temperatures ranging from 56‚ÄØ¬∞F (13‚ÄØ¬∞C) in the morning to 68‚ÄØ¬∞F (20‚ÄØ¬∞C) in the afternoon, with a chance of light rain and generally clear skies.\n",
      "\n",
      "Let me know if there‚Äôs anything else you‚Äôd like to know!"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])\n",
    "    if chunk[0] == \"values\":\n",
    "        print(chunk[1][\"messages\"][-1].content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
